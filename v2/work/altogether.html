<!DOCTYPE html>
<html lang="en">
<head>
  <!-- HTML Meta Tags -->
  <title>ALTogether - Danielle Cruz</title>

  <!-- CSS and JS files-->
  <link rel="stylesheet" href="../styles.css">
  </head>
  <body>
    
    <!-- Left -->
    <div id="sidebar">
      <div id="name">
        <a href="#"><h1>Danielle Cruz</h1></a>
      </div>
      <div id="menu">
        <ul class="no-bullets">
          <li><a href="#">Work</a></li>
          <li><a href="#">Audio</a></li>
          <li><a href="#">Other</a></li>
          <li><a href="#">About</a></li>
        </ul>
      </div>
    </div>
    
    <!-- Right -->
    <div id="content">
      <!-- Header-->
      <header>
      </header>

      <!-- -->
      
      <main id="altogether">
        <div class="two-column feature">
          <div class="minor">
            <section>
              <h1>ALTogether</h1>
              <h2>creating richer, more reliable alt text</h2>
            </section>
            
            
            <section>
              <p>
                Images play such a huge role on social media platforms; however, the notion of alt text is unknown to many sighted users, hence leaving countless photos without alt text descriptions. ALTogether is a concept for an Instagram extension which helps sighted users to write quality alt text by modifying AI-generated suggestions on their images.
              </p>

              <p>
                Developed with Haeli Baek, Jung-Won Ha, and Sydney Jones. <a href="#">View final report</a>.
              </p>
              
            </section>
            
          </div>
          <div class="major">
            <figure>
              <iframe src="https://www.youtube.com/embed/1Os8VLGGnlA?si=YGE7wdCfLPwINsAP" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
              <figcaption>ALTogether (concept video), 2021.</figcaption>
            </figure>
          </div>


        </div>
        <!-- <div class="two-column">
          <div class="minor">
            <section>
              <h2>what's alt text?</h2>
            </section>
             </div>
            <div class="major">
            <p>
              To interact with images on webpages and digital platforms, many people who are blind or visually-impaired use a screen reader to access written descriptions of these photos. This description is called alt text, and people can add it to images to make the visual information being conveyed accessible to those who can't see it.
            </p>
          </div>
        </div> -->
        <div class="two-column">
          <div class="minor">
            <section>
              <h2>what's alt text?</h2>
              <p>
                To interact with images on webpages and digital platforms, many people who are blind or visually-impaired use a screen reader to access written descriptions of these photos. This description is called alt text, and people can add it to images to make the visual information being conveyed accessible to those who can't see it.
              </p>
            </section>
            <!-- <section>
              <h2>problem</h2>
              <p>
                After interviewing 6 blind and visually-impaired users, we discovered that alt text isn’t included in the overwhelming majority of images posted online. One 2019 study found that a mere 0.1% of all images on Twitter included alt text, making the other 99.9% of images virtually inaccessible to many blind and visually-impaired users who rely on screen readers to navigate the digital landscape (<a href="#">How User-Provided Image Descriptions Have Failed to Make Twitter Accessible</a>).
              </p>
              <p>
                Sighted users often neglect to write an alt text before they think to upload a photo. Unfortunately, many social media platforms bury the option to add personalized alt text 3-4 extra clicks deep into advanced settings, so users wouldn’t know how to add alt text even if they remembered to. Even more, auto-generated descriptions tend to be inaccurate and lacking in the context and nuance only a human can provide, often leaving blind and visually-impaired users feeling frustrated.
              </p>
              <p>
                "One of my friends shared a photo on Facebook, and the auto-generated alt text read, "may contain sky, grass, bird,” which sounds really serene and idyllic! But the caption clarified the image was actually of a creepy, dead crow... The alt text didn't really capture the point of the image."
                — One blind user whom we interviewed
              </p>
            </section> -->
            </div>
            <div class="major">
              <figure>
                <img src="../assets/images/alt-text.png">
                <figcaption>An example of an Instagram post with exposed alt text.</figcaption>
              </figure>
          </div>
        </div>
        <div class="two-column">
          <div class="minor">
            <!-- <section>
              <h2>what's alt text?</h2>
              <p>
                To interact with images on webpages and digital platforms, many people who are blind or visually-impaired use a screen reader to access written descriptions of these photos. This description is called alt text, and people can add it to images to make the visual information being conveyed accessible to those who can't see it.
              </p>
            </section> -->
            <section>
              <h2>problem</h2>
              <p>
                After interviewing 6 blind and visually-impaired users, we discovered that alt text isn’t included in the overwhelming majority of images posted online. One 2019 study found that a mere 0.1% of all images on Twitter included alt text, making the other 99.9% of images virtually inaccessible to many blind and visually-impaired users who rely on screen readers to navigate the digital landscape (<a href="#">How User-Provided Image Descriptions Have Failed to Make Twitter Accessible</a>).
              </p>
              <p>
                Sighted users often neglect to write an alt text before they think to upload a photo. Unfortunately, many social media platforms bury the option to add personalized alt text 3-4 extra clicks deep into advanced settings, so users wouldn’t know how to add alt text even if they remembered to. Even more, auto-generated descriptions tend to be inaccurate and lacking in the context and nuance only a human can provide, often leaving blind and visually-impaired users feeling frustrated.
              </p>
            </section>
          </div>
          <div class="major">
            <article class="block-quote">
              <p>
                "One of my friends shared a photo on Facebook, and the auto-generated alt text read, "may contain sky, grass, bird,” which sounds really serene and idyllic! But the caption clarified the image was actually of a creepy, dead crow... The alt text didn't really capture the point of the image."
              </p>
              <p class="block-quote-credit">
                — One blind user whom we interviewed
              </p>
            </article>
          </div>
        </div>

        <!-- <div class="two-column">
          <div class="minor">

            <section>
              <h2>problem</h2>
              <p>
                After interviewing 6 blind and visually-impaired users, we discovered that alt text isn’t included in the overwhelming majority of images posted online. One 2019 study found that a mere 0.1% of all images on Twitter included alt text, making the other 99.9% of images virtually inaccessible to many blind and visually-impaired users who rely on screen readers to navigate the digital landscape (<a href="#">How User-Provided Image Descriptions Have Failed to Make Twitter Accessible</a>).
              </p>
              <p>
                Sighted users often neglect to write an alt text before they think to upload a photo. Unfortunately, many social media platforms bury the option to add personalized alt text 3-4 extra clicks deep into advanced settings, so users wouldn’t know how to add alt text even if they remembered to. Even more, auto-generated descriptions tend to be inaccurate and lacking in the context and nuance only a human can provide, often leaving blind and visually-impaired users feeling frustrated.
              </p>
              <p>
                "One of my friends shared a photo on Facebook, and the auto-generated alt text read, "may contain sky, grass, bird,” which sounds really serene and idyllic! But the caption clarified the image was actually of a creepy, dead crow... The alt text didn't really capture the point of the image."
                — One blind user whom we interviewed
              </p>
            </section>
            
          </div>
          <div class="minor">
            <section>
              <h2>prototyping</h2>
              <p>
                After three rounds of testing, we validated our assumption that writing alt text isn’t primarily a question of time or effort but rather of awareness. Once users understood what alt text was, they liked the idea of writing it to make their feeds more accessible. We also found that since most sighted users didn’t know what alt text was, they didn’t know what best practices to adopt when writing one. Some alt texts they wrote were underdescriptive and others were paragraphs too long. Sighted users didn't know which details were the most important to include when capturing the image. 
              </p>
              <p>
                This revealed a tension between blind and visually-impaired users' needs for quality and accurate alt texts and sighted users' inexperience in writing them. 
              </p>
            </section>
          </div>
        </div> -->

        <div class="two-column">
          <div class="minor">

            <section>
              <h2>prototyping</h2>
              <p>
                After three rounds of testing, we validated our assumption that writing alt text isn’t primarily a question of time or effort but rather of awareness. Once users understood what alt text was, they liked the idea of writing it to make their feeds more accessible. We also found that since most sighted users didn’t know what alt text was, they didn’t know what best practices to adopt when writing one. Some alt texts they wrote were underdescriptive and others were paragraphs too long. Sighted users didn't know which details were the most important to include when capturing the image. 
              </p>
              <p>
                This revealed a tension between blind and visually-impaired users' needs for quality and accurate alt texts and sighted users' inexperience in writing them. 
              </p>
            </section>
          </div>
        </div>

        <div class="two-column">
          <div class="minor">

            <section>
              <h2>solution</h2>
              <p>
                ALTogether is a concept for an Instagram extension that brings alt text to the forefront.
              </p>
              <p>
                It embeds the alt text writing process into the regular flow of posting a photo, making alt text (or the lack thereof) visible on all posts. Not only does ALTogether remind sighted users to include alt text, but it also guides them through the process of writing it, providing an auto-generated suggestion which they easily modify and personalize before posting. This helps ensure that alt texts written with ALTogether actually follow best practices without overwhelming the user to write an entire alt text from scratch. 
              </p>
              <p>
                Ultimately, ALTogether seeks to increase awareness of accessibility needs for blind and visually-impaired users, encouraging sighted users to adopt alt text practices and motivate their followers to do the same.
              </p>
            </section>
            <!-- <section>
              <h2>recognition</h2>
              <p>
                We presented ALTogether at the 2021 Design Thinking for User Experience Design (dt+UX) Expo at Stanford University and received awards for Most Societal Impact, Best Demo, Best Pitch, and Best Concept Video.
              </p>
            </section> -->
          </div>
          <div class="major">
            <figure>
              <iframe src="https://www.youtube.com/embed/N1UOy6KGVgs?si=0x-SxpxlZjN_g89_" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
              <figcaption>ALTogether (demo video), 2021.</figcaption>
            </figure>
          </div>
        </div>

        <div class="two-column">
          <div class="minor">

            <section>
              <h2>recognition</h2>
              <p>
                We presented ALTogether at the 2021 Design Thinking for User Experience Design (dt+UX) Expo at Stanford University and received awards for Most Societal Impact, Best Demo, Best Pitch, and Best Concept Video.
              </p>
            </section>
          </div>
        </div>


      </main>

      <footer>
        Built by Danielle Cruz, 2023.
      </footer>

    </div>
    
    
  </body>
  </html>
  